TERMS: frequency, entropy, fusion
COLORS: green, red, green
CONTENT:
<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns:opensearch="http://a9.com/-/spec/opensearch/1.1/" xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns="http://www.w3.org/2005/Atom">
  <id>https://arxiv.org/api/kTJEAAcq9rQCh1K+MEfMfdvRNlg</id>
  <title>arXiv Query: search_query=all:frequency AND all:entropy AND all:fusion&amp;id_list=&amp;start=0&amp;max_results=3</title>
  <updated>2025-12-01T01:09:51Z</updated>
  <link href="https://arxiv.org/api/query?search_query=all:frequency+AND+(all:entropy+AND+all:fusion)&amp;start=0&amp;max_results=3&amp;id_list=" type="application/atom+xml"/>
  <opensearch:itemsPerPage>3</opensearch:itemsPerPage>
  <opensearch:totalResults>21</opensearch:totalResults>
  <opensearch:startIndex>0</opensearch:startIndex>
  <entry>
    <id>http://arxiv.org/abs/1107.3348v2</id>
    <title>Arithmetic and Frequency Filtering Methods of Pixel-Based Image Fusion Techniques</title>
    <updated>2011-07-19T05:20:59Z</updated>
    <link href="https://arxiv.org/abs/1107.3348v2" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1107.3348v2" rel="related" type="application/pdf" title="pdf"/>
    <summary>In remote sensing, image fusion technique is a useful tool used to fuse high spatial resolution panchromatic images (PAN) with lower spatial resolution multispectral images (MS) to create a high spatial resolution multispectral of image fusion (F) while preserving the spectral information in the multispectral image (MS).There are many PAN sharpening techniques or Pixel-Based image fusion techniques that have been developed to try to enhance the spatial resolution and the spectral property preservation of the MS. This paper attempts to undertake the study of image fusion, by using two types of pixel-based image fusion techniques i.e. Arithmetic Combination and Frequency Filtering Methods of Pixel-Based Image Fusion Techniques. The first type includes Brovey Transform (BT), Color Normalized Transformation (CN) and Multiplicative Method (MLT). The second type include High-Pass Filter Additive Method (HPFA), High-Frequency-Addition Method (HFA) High Frequency Modulation Method (HFM) and The Wavelet transform-based fusion method (WT). This paper also devotes to concentrate on the analytical techniques for evaluating the quality of image fusion (F) by using various methods including Standard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to estimate the quality and degree of information improvement of a fused image quantitatively.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2011-07-18T01:41:37Z</published>
    <arxiv:comment>Image Fusion, Pixel-Based Fusion, Brovey Transform, Color Normalized, High-Pass Filter, Modulation, Wavelet transform</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <arxiv:journal_ref>Journal-ref: International Journal of Advanced Research in Computer Science,Volume 2, No. 5, Sept-Oct 2011,www.ijarcs.info</arxiv:journal_ref>
    <author>
      <name>Firouz Abdullah Al-Wassai</name>
    </author>
    <author>
      <name>N. V. Kalyankar</name>
    </author>
    <author>
      <name>Ali A. Al-Zuky</name>
    </author>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/1212.0318v1</id>
    <title>Comparison of Fuzzy and Neuro Fuzzy Image Fusion Techniques and its Applications</title>
    <updated>2012-12-03T08:55:52Z</updated>
    <link href="https://arxiv.org/abs/1212.0318v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/1212.0318v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Image fusion is the process of integrating multiple images of the same scene into a single fused image to reduce uncertainty and minimizing redundancy while extracting all the useful information from the source images. Image fusion process is required for different applications like medical imaging, remote sensing, medical imaging, machine vision, biometrics and military applications where quality and critical information is required. In this paper, image fusion using fuzzy and neuro fuzzy logic approaches utilized to fuse images from different sensors, in order to enhance visualization. The proposed work further explores comparison between fuzzy based image fusion and neuro fuzzy fusion technique along with quality evaluation indices for image fusion like image quality index, mutual information measure, fusion factor, fusion symmetry, fusion index, root mean square error, peak signal to noise ratio, entropy, correlation coefficient and spatial frequency. Experimental results obtained from fusion process prove that the use of the neuro fuzzy based image fusion approach shows better performance in first two test cases while in the third test case fuzzy based image fusion technique gives better results.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <published>2012-12-03T08:55:52Z</published>
    <arxiv:comment>(0975 8887). arXiv admin note: text overlap with arXiv:1209.4535 by other authors</arxiv:comment>
    <arxiv:primary_category term="cs.CV"/>
    <arxiv:journal_ref>International Journal of Computer Applications Volume 43, No.20, 2012, pages: 31 - 37</arxiv:journal_ref>
    <author>
      <name>D. Srinivasa Rao</name>
    </author>
    <author>
      <name>M. Seetha</name>
    </author>
    <author>
      <name>M. H. M. Krishna Prasad</name>
    </author>
    <arxiv:doi>10.5120/6222-8800</arxiv:doi>
    <link rel="related" href="https://doi.org/10.5120/6222-8800" title="doi"/>
  </entry>
  <entry>
    <id>http://arxiv.org/abs/2505.04526v1</id>
    <title>DFVO: Learning Darkness-free Visible and Infrared Image Disentanglement and Fusion All at Once</title>
    <updated>2025-05-07T15:59:45Z</updated>
    <link href="https://arxiv.org/abs/2505.04526v1" rel="alternate" type="text/html"/>
    <link href="https://arxiv.org/pdf/2505.04526v1" rel="related" type="application/pdf" title="pdf"/>
    <summary>Visible and infrared image fusion is one of the most crucial tasks in the field of image fusion, aiming to generate fused images with clear structural information and high-quality texture features for high-level vision tasks. However, when faced with severe illumination degradation in visible images, the fusion results of existing image fusion methods often exhibit blurry and dim visual effects, posing major challenges for autonomous driving. To this end, a Darkness-Free network is proposed to handle Visible and infrared image disentanglement and fusion all at Once (DFVO), which employs a cascaded multi-task approach to replace the traditional two-stage cascaded training (enhancement and fusion), addressing the issue of information entropy loss caused by hierarchical data transmission. Specifically, we construct a latent-common feature extractor (LCFE) to obtain latent features for the cascaded tasks strategy. Firstly, a details-extraction module (DEM) is devised to acquire high-frequency semantic information. Secondly, we design a hyper cross-attention module (HCAM) to extract low-frequency information and preserve texture features from source images. Finally, a relevant loss function is designed to guide the holistic network learning, thereby achieving better image fusion. Extensive experiments demonstrate that our proposed approach outperforms state-of-the-art alternatives in terms of qualitative and quantitative evaluations. Particularly, DFVO can generate clearer, more informative, and more evenly illuminated fusion results in the dark environments, achieving best performance on the LLVIP dataset with 63.258 dB PSNR and 0.724 CC, providing more effective information for high-level vision tasks. Our code is publicly accessible at https://github.com/DaVin-Qi530/DFVO.</summary>
    <category term="cs.CV" scheme="http://arxiv.org/schemas/atom"/>
    <category term="cs.AI" scheme="http://arxiv.org/schemas/atom"/>
    <published>2025-05-07T15:59:45Z</published>
    <arxiv:primary_category term="cs.CV"/>
    <author>
      <name>Qi Zhou</name>
    </author>
    <author>
      <name>Yukai Shi</name>
    </author>
    <author>
      <name>Xiaojun Yang</name>
    </author>
    <author>
      <name>Xiaoyu Xian</name>
    </author>
    <author>
      <name>Lunjia Liao</name>
    </author>
    <author>
      <name>Ruimao Zhang</name>
    </author>
    <author>
      <name>Liang Lin</name>
    </author>
  </entry>
</feed>
